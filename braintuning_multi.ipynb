{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook I'll train a brain to image and text features and combine their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nilearn \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join as opj\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from nilearn import plotting\n",
    "from nilearn.image import *\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import mean_img\n",
    "from nilearn.plotting import plot_img, plot_epi\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import wandb\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataset import fMRI_Dataset, fMRI_Multi_Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from network import Encoder, ContrastiveModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import importlib\n",
    "importlib.reload(dataset)\n",
    "from dataset import fMRI_Dataset, fMRI_Multi_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteoferrante\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matteo/brain_tuning/wandb/run-20241031_100150-x0add1gz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matteoferrante/BrainTuning/runs/x0add1gz' target=\"_blank\">scary-warlock-6</a></strong> to <a href='https://wandb.ai/matteoferrante/BrainTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matteoferrante/BrainTuning' target=\"_blank\">https://wandb.ai/matteoferrante/BrainTuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matteoferrante/BrainTuning/runs/x0add1gz' target=\"_blank\">https://wandb.ai/matteoferrante/BrainTuning/runs/x0add1gz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/matteoferrante/BrainTuning/runs/x0add1gz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x791036f67ac0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"BrainTuning\",config={\"model\":\"multimodal_model\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "source": [
    "## load the data\n",
    "\n",
    "train_datasets_images=[]\n",
    "val_datasets_images=[]\n",
    "test_datasets_images=[]\n",
    "\n",
    "train_datasets_text=[]\n",
    "val_datasets_text=[]\n",
    "test_datasets_text=[]\n",
    "\n",
    "\n",
    "for subj in tqdm.tqdm([\"CSI1\",\"CSI2\",\"CSI3\",\"CSI4\"]):\n",
    "\n",
    "    subj_id = int(subj.split(\"CSI\")[1])\n",
    "\n",
    "    data_path =  f\"/home/matteo/storage/brain_tuning/{subj}\"\n",
    "\n",
    "    train_fmri = np.load(opj(data_path, \"train_fmri_top.npy\"))\n",
    "    val_fmri = np.load(opj(data_path, \"val_fmri_top.npy\"))\n",
    "    test_fmri = np.load(opj(data_path, \"test_fmri_top.npy\"))\n",
    "\n",
    "    ##load the images\n",
    "    img_train = np.load(opj(data_path, \"img_train.npy\"),allow_pickle=True)\n",
    "    img_val = np.load(opj(data_path, \"img_val.npy\"),allow_pickle=True)\n",
    "    img_test = np.load(opj(data_path, \"img_test.npy\"),allow_pickle=True)\n",
    "\n",
    "     ##load the captions\n",
    "    train_captions = np.load(opj(data_path, \"train_captions.npy\"),allow_pickle=True)\n",
    "    val_captions = np.load(opj(data_path, \"val_captions.npy\"),allow_pickle=True)\n",
    "    test_captions = np.load(opj(data_path, \"test_captions.npy\"),allow_pickle=True)\n",
    "\n",
    "    ## load the features\n",
    "    train_features = np.load(opj(data_path, \"train_image_features.npy\"))\n",
    "    val_features = np.load(opj(data_path, \"val_image_features.npy\"))\n",
    "    test_features = np.load(opj(data_path, \"test_image_features.npy\"))\n",
    "\n",
    "    ## load the text features\n",
    "    train_text_features = np.load(opj(data_path, \"train_text_features.npy\"))\n",
    "    val_text_features = np.load(opj(data_path, \"val_text_features.npy\"))\n",
    "    test_text_features = np.load(opj(data_path, \"test_text_features.npy\"))\n",
    "\n",
    "    ## create the dataset\n",
    "    train_dataset = fMRI_Multi_Dataset(train_fmri,img_train,train_captions,train_features,train_text_features,subj_id,feature_type=\"image\")\n",
    "    val_dataset = fMRI_Multi_Dataset(val_fmri,img_val,val_captions,val_features,val_text_features,subj_id,feature_type=\"image\")\n",
    "    test_dataset = fMRI_Multi_Dataset(test_fmri,img_test,test_captions,test_features,test_text_features, subj_id,feature_type=\"image\")\n",
    "\n",
    "    ## append the datasets\n",
    "    train_datasets_images.append(train_dataset)\n",
    "    val_datasets_images.append(val_dataset)\n",
    "    test_datasets_images.append(test_dataset)\n",
    "\n",
    "    train_dataset_text = fMRI_Multi_Dataset(train_fmri,img_train,train_captions,train_features,train_text_features,subj_id,feature_type=\"text\")\n",
    "    val_dataset_text = fMRI_Multi_Dataset(val_fmri,img_val,val_captions,val_features,val_text_features,subj_id,feature_type=\"text\")\n",
    "    test_dataset_text = fMRI_Multi_Dataset(test_fmri,img_test,test_captions,test_features,test_text_features,subj_id,feature_type=\"text\")\n",
    "\n",
    "    ## append the datasets\n",
    "    train_datasets_text.append(train_dataset_text)\n",
    "    val_datasets_text.append(val_dataset_text)\n",
    "    test_datasets_text.append(test_dataset_text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the datasets\n",
    "train_dataset_images = torch.utils.data.ConcatDataset(train_datasets)\n",
    "val_dataset_images = torch.utils.data.ConcatDataset(val_datasets)\n",
    "test_dataset_images = torch.utils.data.ConcatDataset(test_datasets)\n",
    "\n",
    "train_dataset_text = torch.utils.data.ConcatDataset(train_datasets_text)\n",
    "val_dataset_text = torch.utils.data.ConcatDataset(val_datasets_text)\n",
    "test_dataset_text = torch.utils.data.ConcatDataset(test_datasets_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "train_loader = DataLoader(train_dataset_images, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_images, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset_images, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_loader_text = DataLoader(train_dataset_text, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_text = DataLoader(val_dataset_text, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader_text = DataLoader(test_dataset_text, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an Brain2ImageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimal parameter obtained from the hyperparameter search\n",
    "\n",
    "act_fn = nn.Identity\n",
    "base_channel_size = [2048]\n",
    "hidden_dims = [1024]\n",
    "latent_dim = 768\n",
    "\n",
    "loss_type = \"contrastive\"\n",
    "lr = 1e-4\n",
    "temperature = 0.1\n",
    "wd = 1e-5\n",
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/matteo/anaconda3/envs/borg/lib/python3.8/site- ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241031_100723-9log9fzm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matteoferrante/lightning_logs/runs/9log9fzm' target=\"_blank\">fearsome-skeleton-3</a></strong> to <a href='https://wandb.ai/matteoferrante/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matteoferrante/lightning_logs' target=\"_blank\">https://wandb.ai/matteoferrante/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matteoferrante/lightning_logs/runs/9log9fzm' target=\"_blank\">https://wandb.ai/matteoferrante/lightning_logs/runs/9log9fzm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:477: The total number of parameters detected may be inaccurate because the model contains an instance of `UninitializedParameter`. To get an accurate number, set `self.example_input_array` in your LightningModule.\n",
      "\n",
      "  | Name  | Type    | Params | Mode \n",
      "------------------------------------------\n",
      "0 | model | Encoder | 9.7 K  | train\n",
      "------------------------------------------\n",
      "9.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.7 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 512. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (27) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 27/27 [00:24<00:00,  1.09it/s, v_num=9fzm, train_loss_step=5.120]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 317. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 27/27 [00:28<00:00,  0.95it/s, v_num=9fzm, train_loss_step=5.120, val_loss=5.440, val_mse_loss=1.720, val_cosine_similarity=0.120, train_loss_epoch=5.800]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 359. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "Metric val_loss improved. New best score: 5.441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 27/27 [00:27<00:00,  0.98it/s, v_num=9fzm, train_loss_step=4.420, val_loss=5.220, val_mse_loss=1.660, val_cosine_similarity=0.153, train_loss_epoch=5.010]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.223 >= min_delta = 0.0. New best score: 5.218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 27/27 [00:25<00:00,  1.05it/s, v_num=9fzm, train_loss_step=4.120, val_loss=5.100, val_mse_loss=1.630, val_cosine_similarity=0.167, train_loss_epoch=4.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.117 >= min_delta = 0.0. New best score: 5.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 27/27 [00:36<00:00,  0.74it/s, v_num=9fzm, train_loss_step=3.830, val_loss=5.040, val_mse_loss=1.620, val_cosine_similarity=0.174, train_loss_epoch=4.270]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.060 >= min_delta = 0.0. New best score: 5.041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 27/27 [00:43<00:00,  0.62it/s, v_num=9fzm, train_loss_step=3.520, val_loss=5.000, val_mse_loss=1.610, val_cosine_similarity=0.177, train_loss_epoch=3.980]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.038 >= min_delta = 0.0. New best score: 5.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 27/27 [00:48<00:00,  0.56it/s, v_num=9fzm, train_loss_step=3.320, val_loss=4.990, val_mse_loss=1.610, val_cosine_similarity=0.177, train_loss_epoch=3.730]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 4.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 27/27 [00:35<00:00,  0.76it/s, v_num=9fzm, train_loss_step=3.120, val_loss=4.980, val_mse_loss=1.610, val_cosine_similarity=0.175, train_loss_epoch=3.520]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 4.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 27/27 [00:25<00:00,  1.07it/s, v_num=9fzm, train_loss_step=2.960, val_loss=4.990, val_mse_loss=1.620, val_cosine_similarity=0.173, train_loss_epoch=3.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 4.984. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 27/27 [00:25<00:00,  1.05it/s, v_num=9fzm, train_loss_step=2.960, val_loss=4.990, val_mse_loss=1.620, val_cosine_similarity=0.173, train_loss_epoch=3.330]\n"
     ]
    }
   ],
   "source": [
    "brain_image_model = ContrastiveModel(num_input_channels= 10000,\n",
    "                                base_channel_size=base_channel_size, \n",
    "                                hidden_dims=hidden_dims,\n",
    "                                latent_dim=latent_dim,\n",
    "                                act_fn=act_fn,\n",
    "                                loss_type=loss_type,\n",
    "                                lr = lr,\n",
    "                                wd = wd,\n",
    "                                alpha=alpha)\n",
    "\n",
    "# Set up early stopping to monitor 'val_loss'\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=1,verbose=True, mode='min')             # 'min' because we want to minimize val_loss\n",
    "wandb_logger = WandbLogger()  # Logs the model and metrics to wandb\n",
    "\n",
    "\n",
    "# Set up early stopping to monitor 'val_loss'\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=1,verbose=True, mode='min')             # 'min' because we want to minimize val_loss\n",
    "wandb_logger = WandbLogger()  # Logs the model and metrics to wandb\n",
    "\n",
    "\n",
    "# Create a unique checkpoint directory based on the run name or ID\n",
    "run_name = \"multimodal_model_IMAGE\"\n",
    "checkpoint_dir = os.path.join(data_path, \"models_multi\", run_name)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Model checkpoint configuration\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss',dirpath=checkpoint_dir,filename='brain_image_model-{epoch:02d}-{val_loss:.2f}',save_top_k=3,mode='min',)\n",
    "\n",
    "\n",
    "# Initialize trainer with logger\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, devices=[1], callbacks=[early_stop_callback,checkpoint_callback],logger=wandb_logger ) # Add the wandb logger here\n",
    "\n",
    "trainer.fit(brain_image_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/matteo/anaconda3/envs/borg/lib/python3.8/site- ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  | Name  | Type    | Params | Mode \n",
      "------------------------------------------\n",
      "0 | model | Encoder | 9.2 K  | train\n",
      "------------------------------------------\n",
      "9.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.2 K     Total params\n",
      "0.037     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (27) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 27/27 [00:28<00:00,  0.94it/s, v_num=9fzm, train_loss_step=5.160, val_loss=5.530, val_mse_loss=1.800, val_cosine_similarity=0.111, train_loss_epoch=5.860]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 5.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 27/27 [00:26<00:00,  1.01it/s, v_num=9fzm, train_loss_step=4.530, val_loss=5.350, val_mse_loss=1.750, val_cosine_similarity=0.138, train_loss_epoch=5.080]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.184 >= min_delta = 0.0. New best score: 5.347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 27/27 [00:23<00:00,  1.14it/s, v_num=9fzm, train_loss_step=4.150, val_loss=5.270, val_mse_loss=1.730, val_cosine_similarity=0.148, train_loss_epoch=4.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.077 >= min_delta = 0.0. New best score: 5.270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 27/27 [00:26<00:00,  1.02it/s, v_num=9fzm, train_loss_step=3.860, val_loss=5.240, val_mse_loss=1.720, val_cosine_similarity=0.152, train_loss_epoch=4.290]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.0. New best score: 5.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 27/27 [00:30<00:00,  0.89it/s, v_num=9fzm, train_loss_step=3.650, val_loss=5.240, val_mse_loss=1.720, val_cosine_similarity=0.152, train_loss_epoch=3.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 5.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 27/27 [00:31<00:00,  0.86it/s, v_num=9fzm, train_loss_step=3.360, val_loss=5.250, val_mse_loss=1.730, val_cosine_similarity=0.150, train_loss_epoch=3.730]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 5.241. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 27/27 [00:31<00:00,  0.85it/s, v_num=9fzm, train_loss_step=3.360, val_loss=5.250, val_mse_loss=1.730, val_cosine_similarity=0.150, train_loss_epoch=3.730]\n"
     ]
    }
   ],
   "source": [
    "brain_text_model = ContrastiveModel(num_input_channels= 10000,\n",
    "                                base_channel_size=base_channel_size, \n",
    "                                hidden_dims=hidden_dims,\n",
    "                                latent_dim=512,\n",
    "                                act_fn=act_fn,\n",
    "                                loss_type=loss_type,\n",
    "                                lr = lr,\n",
    "                                wd = wd,\n",
    "                                alpha=alpha)\n",
    "\n",
    "# Set up early stopping to monitor 'val_loss'\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=1,verbose=True, mode='min')             # 'min' because we want to minimize val_loss\n",
    "wandb_logger = WandbLogger()  # Logs the model and metrics to wandb\n",
    "\n",
    "\n",
    "# Set up early stopping to monitor 'val_loss'\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=1,verbose=True, mode='min')             # 'min' because we want to minimize val_loss\n",
    "wandb_logger = WandbLogger()  # Logs the model and metrics to wandb\n",
    "\n",
    "\n",
    "# Create a unique checkpoint directory based on the run name or ID\n",
    "run_name = run_name = \"multimodal_model_TEXT\"\n",
    "\n",
    "checkpoint_dir = os.path.join(data_path, \"models_multi\", run_name)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Model checkpoint configuration\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss',dirpath=checkpoint_dir,filename='TEXT_brain_text_model-{epoch:02d}-{val_loss:.2f}',save_top_k=3,mode='min',)\n",
    "\n",
    "\n",
    "# Initialize trainer with logger\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, devices=[1], callbacks=[early_stop_callback,checkpoint_callback],logger=wandb_logger ) # Add the wandb logger here\n",
    "\n",
    "trainer.fit(brain_text_model, train_loader_text, val_loader_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Evaluation:\n",
    "\n",
    "I'll wrap both models in a class, run predictions and concatenate outputs for subsequent evalautions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModelWrapper(nn.Module):\n",
    "    def __init__(self, image_model, text_model):\n",
    "        super(MultimodalModelWrapper, self).__init__()\n",
    "        self.image_model = image_model\n",
    "        self.text_model = text_model\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Extract relevant features from the batch\n",
    "\n",
    "        x = batch[\"data\"]\n",
    "        text_embed = batch[\"text_features\"]\n",
    "        img_embed = batch[\"image_features\"]\n",
    "        k = batch[\"subject_id\"]\n",
    "        # Pass features through each model\n",
    "        image_output,_ = self.image_model(x,img_embed,k=k)\n",
    "        text_output,_ = self.text_model(x,text_embed,k=k)\n",
    "\n",
    "        concatenated_embeddings = torch.cat((img_embed, text_embed), dim=-1)\n",
    "\n",
    "        # Concatenate outputs along the last dimension\n",
    "        combined_output = torch.cat((image_output, text_output), dim=-1)  # Shape: (batch_size, combined_dim)\n",
    "\n",
    "        return combined_output, concatenated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_model = MultimodalModelWrapper(brain_image_model, brain_text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Evaluating metrics for subject 1...\n",
      "Computed similarity matrix for subject 1.\n",
      "Top-1 Accuracy: 0.0583, Top-5 Accuracy: 0.1939 for subject 1.\n",
      "Identification accuracy for subject 1: 0.9229\n",
      "Logged top-5 retrievals for subject 1.\n",
      "Evaluating metrics for subject 2...\n",
      "Computed similarity matrix for subject 2.\n",
      "Top-1 Accuracy: 0.0368, Top-5 Accuracy: 0.1191 for subject 2.\n",
      "Identification accuracy for subject 2: 0.8924\n",
      "Logged top-5 retrievals for subject 2.\n",
      "Evaluating metrics for subject 3...\n",
      "Computed similarity matrix for subject 3.\n",
      "Top-1 Accuracy: 0.0266, Top-5 Accuracy: 0.1305 for subject 3.\n",
      "Identification accuracy for subject 3: 0.8857\n",
      "Logged top-5 retrievals for subject 3.\n",
      "Evaluating metrics for subject 4...\n",
      "Computed similarity matrix for subject 4.\n",
      "Top-1 Accuracy: 0.0343, Top-5 Accuracy: 0.1370 for subject 4.\n",
      "Identification accuracy for subject 4: 0.8635\n",
      "Logged top-5 retrievals for subject 4.\n",
      "Evaluation complete. Results loaded to wandb.\n"
     ]
    }
   ],
   "source": [
    "import importlib \n",
    "import multi_evaluation\n",
    "importlib.reload(multi_evaluation)\n",
    "from multi_evaluation import *\n",
    "results_df, similarity_matrices, results = evaluate_and_log(test_loader_text,multimodal_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Identification Accuracy (%)</th>\n",
       "      <th>ID Accuracy Baseline (%)</th>\n",
       "      <th>Top-1 Accuracy (%)</th>\n",
       "      <th>Top1 Baseline (%)</th>\n",
       "      <th>Top1 Improvement Over Baseline</th>\n",
       "      <th>Top-5 Accuracy (%)</th>\n",
       "      <th>Top5 Baseline (%)</th>\n",
       "      <th>Top5 Improvement Over Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>92.293142</td>\n",
       "      <td>50</td>\n",
       "      <td>5.830165</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.391635</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>89.242793</td>\n",
       "      <td>50</td>\n",
       "      <td>3.675539</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.913815</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>88.574337</td>\n",
       "      <td>50</td>\n",
       "      <td>2.661597</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.054499</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>86.345131</td>\n",
       "      <td>50</td>\n",
       "      <td>3.426124</td>\n",
       "      <td>0.214133</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.704497</td>\n",
       "      <td>1.070664</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject  Identification Accuracy (%)  ID Accuracy Baseline (%)  \\\n",
       "0        1                    92.293142                        50   \n",
       "1        2                    89.242793                        50   \n",
       "2        3                    88.574337                        50   \n",
       "3        4                    86.345131                        50   \n",
       "\n",
       "   Top-1 Accuracy (%)  Top1 Baseline (%)  Top1 Improvement Over Baseline  \\\n",
       "0            5.830165           0.126743                            46.0   \n",
       "1            3.675539           0.126743                            29.0   \n",
       "2            2.661597           0.126743                            21.0   \n",
       "3            3.426124           0.214133                            16.0   \n",
       "\n",
       "   Top-5 Accuracy (%)  Top5 Baseline (%)  Top5 Improvement Over Baseline  \n",
       "0           19.391635           0.633714                            30.6  \n",
       "1           11.913815           0.633714                            18.8  \n",
       "2           13.054499           0.633714                            20.6  \n",
       "3           13.704497           1.070664                            12.8  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/home/matteo/storage/brain_tuning/\"\n",
    "results_df.to_csv(opj(output_path,\"results_multi_contrastive.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
