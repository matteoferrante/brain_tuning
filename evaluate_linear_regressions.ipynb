{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Notebook to evaluate the performances of linear decoding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import himalaya\n",
    "import os\n",
    "import torch\n",
    "from himalaya.backend import set_backend\n",
    "from os.path import join as opj\n",
    "import pickle\n",
    "from himalaya.ridge import RidgeCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification accuracy function\n",
    "def identification_accuracy_fast(P, T):\n",
    "    n = P.shape[0]\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "\n",
    "    P_mean = np.mean(P, axis=1, keepdims=True)\n",
    "    T_mean = np.mean(T, axis=1, keepdims=True)\n",
    "    P_std = np.std(P, axis=1, keepdims=True)\n",
    "    T_std = np.std(T, axis=1, keepdims=True)\n",
    "    \n",
    "    P_normalized = (P - P_mean) / P_std\n",
    "    T_normalized = (T - T_mean) / T_std\n",
    "    C = np.dot(P_normalized, T_normalized.T) / P.shape[1]\n",
    "\n",
    "    id_acc = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        id_acc[i] = (C[i, i] >= C[i]).sum()  \n",
    "        id_acc[i] = id_acc[i] / (n - 1)\n",
    "    \n",
    "    return np.mean(id_acc)\n",
    "\n",
    "\n",
    "def evaluate_and_log(y_pred,y_gt,subject_id):\n",
    "    \n",
    "    \n",
    "    y_pred_np = y_pred\n",
    "    y_gt_np = y_gt\n",
    "\n",
    "    # Compute similarity matrix\n",
    "    similarity_matrix = cosine_similarity(y_pred_np, y_gt_np)\n",
    "\n",
    "    # Calculate Top-1 and Top-5 accuracy\n",
    "    top1_acc = 100*(np.argmax(similarity_matrix, axis=1) == np.arange(len(y_gt_np))).mean()\n",
    "    top5_acc = 100*np.mean([1 if i in np.argsort(-similarity_matrix[i])[:5] else 0 for i in range(len(y_gt_np))])\n",
    "    print(f\"Top-1 Accuracy: {top1_acc:.4f}, Top-5 Accuracy: {top5_acc:.4f} \")\n",
    "\n",
    "    # Identification accuracy\n",
    "    id_acc = 100*identification_accuracy_fast(y_pred_np, y_gt_np)\n",
    "    print(f\"Identification accuracy: {id_acc:.4f}\")\n",
    "\n",
    "    baseline_top1 = 100/len(y_gt_np)\n",
    "    baseline_top5 = 500/len(y_gt_np)\n",
    "\n",
    "    improvement_top1 = top1_acc/baseline_top1\n",
    "    improvement_top5 = top5_acc/baseline_top5\n",
    "    # Baseline performance (50% for identification accuracy as requested)\n",
    "    id_acc_baseline = 50\n",
    "    results = { \"Subject\": subject_id,\n",
    "\n",
    "        \"Identification Accuracy (%)\": id_acc,\n",
    "        \"ID Accuracy Baseline (%)\": id_acc_baseline,\n",
    "        \"Top-1 Accuracy (%)\": top1_acc,\n",
    "        \"Top1 Baseline (%)\": baseline_top1,\n",
    "        \"Top1 Improvement Over Baseline\": improvement_top1,\n",
    "        \"Top-5 Accuracy (%)\": top5_acc,\n",
    "        \"Top5 Baseline (%)\": baseline_top5,\n",
    "        \"Top5 Improvement Over Baseline\": improvement_top5}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image linear decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/home/matteo/anaconda3/envs/braindiff/lib/python3.8/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 3795 < 10000). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 1/4 [00:07<00:21,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 7.7313, Top-5 Accuracy: 24.5881 \n",
      "Identification accuracy: 94.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/braindiff/lib/python3.8/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 3795 < 10000). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n",
      " 50%|█████     | 2/4 [00:14<00:14,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 4.8162, Top-5 Accuracy: 15.4626 \n",
      "Identification accuracy: 91.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/braindiff/lib/python3.8/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 3795 < 10000). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 3/4 [00:22<00:07,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 5.1965, Top-5 Accuracy: 16.3498 \n",
      "Identification accuracy: 91.5687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/braindiff/lib/python3.8/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 2244 < 10000). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:25<00:00,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 4.2827, Top-5 Accuracy: 17.7730 \n",
      "Identification accuracy: 91.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/matteo/storage/brain_tuning\"\n",
    "\n",
    "image_results = []\n",
    "image_models = {}\n",
    "\n",
    "for i, subj in tqdm.tqdm(enumerate([\"CSI1\",\"CSI2\",\"CSI3\",\"CSI4\"]),total=4):\n",
    "\n",
    "    #Load test fMRI data, test features and decoding model\n",
    "\n",
    "\n",
    "    ## encode the augmented images using the image encoding model \n",
    "    device_id = 0\n",
    "    torch.cuda.set_device(device_id)  # Set the current device\n",
    "\n",
    "    device = f\"cuda:{device_id}\"\n",
    "    backend = set_backend(\"torch_cuda\")\n",
    "    data_path =  f\"/home/matteo/storage/brain_tuning/{subj}\"\n",
    "\n",
    "    test_fmri_top = np.load(opj(data_path, \"test_fmri_top.npy\"))\n",
    "    test_features = np.load(opj(data_path, \"test_image_features.npy\"))\n",
    "    train_fmri_top = np.load(opj(data_path, \"train_fmri_top.npy\"))\n",
    "    train_features = np.load(opj(data_path, \"train_image_features.npy\"))\n",
    "\n",
    "    simple_decoding_model = RidgeCV(alphas=[1, 10, 100, 1e3, 1e4])\n",
    "    simple_decoding_model.fit(backend.asarray(train_fmri_top).to(device),backend.asarray(train_features).to(device))\n",
    "\n",
    "    #Use the model to predict test set image features\n",
    "    test_predictions = simple_decoding_model.predict(backend.asarray(test_fmri_top).to(device))\n",
    "\n",
    "\n",
    "\n",
    "    res = evaluate_and_log(test_predictions.numpy(),test_features,i+1)\n",
    "    image_results.append(res)\n",
    "\n",
    "    image_models[subj] = {\"model\":simple_decoding_model, \"test_predictions\":test_predictions, \"test_features\":test_features}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.DataFrame.from_dict(image_results)\n",
    "df_image.to_csv(\"/home/matteo/storage/brain_tuning/results_image_linear.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Identification Accuracy (%)</th>\n",
       "      <th>ID Accuracy Baseline (%)</th>\n",
       "      <th>Top-1 Accuracy (%)</th>\n",
       "      <th>Top1 Baseline (%)</th>\n",
       "      <th>Top1 Improvement Over Baseline</th>\n",
       "      <th>Top-5 Accuracy (%)</th>\n",
       "      <th>Top5 Baseline (%)</th>\n",
       "      <th>Top5 Improvement Over Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94.100352</td>\n",
       "      <td>50</td>\n",
       "      <td>7.731305</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>61.0</td>\n",
       "      <td>24.588086</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>38.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>91.554721</td>\n",
       "      <td>50</td>\n",
       "      <td>4.816223</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.462611</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>91.568714</td>\n",
       "      <td>50</td>\n",
       "      <td>5.196451</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.349810</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>25.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>91.606088</td>\n",
       "      <td>50</td>\n",
       "      <td>4.282655</td>\n",
       "      <td>0.214133</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.773019</td>\n",
       "      <td>1.070664</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject  Identification Accuracy (%)  ID Accuracy Baseline (%)  \\\n",
       "0        0                    94.100352                        50   \n",
       "1        1                    91.554721                        50   \n",
       "2        2                    91.568714                        50   \n",
       "3        3                    91.606088                        50   \n",
       "\n",
       "   Top-1 Accuracy (%)  Top1 Baseline (%)  Top1 Improvement Over Baseline  \\\n",
       "0            7.731305           0.126743                            61.0   \n",
       "1            4.816223           0.126743                            38.0   \n",
       "2            5.196451           0.126743                            41.0   \n",
       "3            4.282655           0.214133                            20.0   \n",
       "\n",
       "   Top-5 Accuracy (%)  Top5 Baseline (%)  Top5 Improvement Over Baseline  \n",
       "0           24.588086           0.633714                            38.8  \n",
       "1           15.462611           0.633714                            24.4  \n",
       "2           16.349810           0.633714                            25.8  \n",
       "3           17.773019           1.070664                            16.6  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text decoding evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/home/matteo/anaconda3/envs/braindiff/lib/python3.8/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 3795 < 10000). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 1/4 [00:07<00:21,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 3.4221, Top-5 Accuracy: 13.9417 \n",
      "Identification accuracy: 90.2831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/braindiff/lib/python3.8/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 3795 < 10000). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n",
      " 50%|█████     | 2/4 [00:15<00:15,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 2.7883, Top-5 Accuracy: 10.7731 \n",
      "Identification accuracy: 86.7171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/braindiff/lib/python3.8/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 3795 < 10000). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 3/4 [00:22<00:07,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 2.2814, Top-5 Accuracy: 9.7592 \n",
      "Identification accuracy: 86.7827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/braindiff/lib/python3.8/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 2244 < 10000). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:25<00:00,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 1.7131, Top-5 Accuracy: 8.7794 \n",
      "Identification accuracy: 85.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/matteo/storage/brain_tuning\"\n",
    "\n",
    "text_results = []\n",
    "text_models = {}\n",
    "\n",
    "for i, subj in tqdm.tqdm(enumerate([\"CSI1\",\"CSI2\",\"CSI3\",\"CSI4\"]),total=4):\n",
    "\n",
    "    #Load test fMRI data, test features and decoding model\n",
    "\n",
    "\n",
    "    ## encode the augmented images using the image encoding model \n",
    "    device_id = 0\n",
    "    torch.cuda.set_device(device_id)  # Set the current device\n",
    "\n",
    "    device = f\"cuda:{device_id}\"\n",
    "    backend = set_backend(\"torch_cuda\")\n",
    "    data_path =  f\"/home/matteo/storage/brain_tuning/{subj}\"\n",
    "\n",
    "    test_fmri_top = np.load(opj(data_path, \"TEXT_test_fmri_top.npy\"))\n",
    "    test_features = np.load(opj(data_path, \"test_text_features.npy\"))\n",
    "    train_fmri_top = np.load(opj(data_path, \"TEXT_train_fmri_top.npy\"))\n",
    "    train_features = np.load(opj(data_path, \"train_text_features.npy\"))\n",
    "\n",
    "    simple_decoding_model = RidgeCV(alphas=[1, 10, 100, 1e3, 1e4])\n",
    "    simple_decoding_model.fit(backend.asarray(train_fmri_top).to(device),backend.asarray(train_features).to(device))\n",
    "\n",
    "    #Use the model to predict test set image features\n",
    "    test_predictions = simple_decoding_model.predict(backend.asarray(test_fmri_top).to(device))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    res = evaluate_and_log(test_predictions.numpy(),test_features,i+1)\n",
    "    text_results.append(res)\n",
    "    text_models[subj] = {\"model\":simple_decoding_model, \"test_predictions\":test_predictions, \"test_features\":test_features}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Identification Accuracy (%)</th>\n",
       "      <th>ID Accuracy Baseline (%)</th>\n",
       "      <th>Top-1 Accuracy (%)</th>\n",
       "      <th>Top1 Baseline (%)</th>\n",
       "      <th>Top1 Improvement Over Baseline</th>\n",
       "      <th>Top-5 Accuracy (%)</th>\n",
       "      <th>Top5 Baseline (%)</th>\n",
       "      <th>Top5 Improvement Over Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>90.283112</td>\n",
       "      <td>50</td>\n",
       "      <td>3.422053</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.941698</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>86.717106</td>\n",
       "      <td>50</td>\n",
       "      <td>2.788340</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.773131</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>86.782730</td>\n",
       "      <td>50</td>\n",
       "      <td>2.281369</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.759189</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>85.209216</td>\n",
       "      <td>50</td>\n",
       "      <td>1.713062</td>\n",
       "      <td>0.214133</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.779443</td>\n",
       "      <td>1.070664</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject  Identification Accuracy (%)  ID Accuracy Baseline (%)  \\\n",
       "0        0                    90.283112                        50   \n",
       "1        1                    86.717106                        50   \n",
       "2        2                    86.782730                        50   \n",
       "3        3                    85.209216                        50   \n",
       "\n",
       "   Top-1 Accuracy (%)  Top1 Baseline (%)  Top1 Improvement Over Baseline  \\\n",
       "0            3.422053           0.126743                            27.0   \n",
       "1            2.788340           0.126743                            22.0   \n",
       "2            2.281369           0.126743                            18.0   \n",
       "3            1.713062           0.214133                             8.0   \n",
       "\n",
       "   Top-5 Accuracy (%)  Top5 Baseline (%)  Top5 Improvement Over Baseline  \n",
       "0           13.941698           0.633714                            22.0  \n",
       "1           10.773131           0.633714                            17.0  \n",
       "2            9.759189           0.633714                            15.4  \n",
       "3            8.779443           1.070664                             8.2  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = pd.DataFrame.from_dict(text_results)\n",
    "df_text.to_csv(\"/home/matteo/storage/brain_tuning/results_text_linear.csv\")\n",
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1721,  0.0232,  0.0613,  ...,  0.0726,  0.0768,  0.2222],\n",
       "        [ 0.0231, -0.1485,  0.1456,  ..., -0.3089,  0.0558, -0.0024],\n",
       "        [-0.4820,  0.5566, -0.2041,  ...,  0.2479, -0.3731,  0.0402],\n",
       "        ...,\n",
       "        [ 0.4915,  0.0975,  0.5601,  ..., -0.1677, -0.0991, -0.1818],\n",
       "        [-0.3734,  0.1420,  0.0088,  ..., -0.4706, -0.2087, -0.2411],\n",
       "        [ 0.0461, -0.1658,  0.0062,  ..., -0.2219, -0.2214,  0.2905]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_models[\"CSI1\"][\"test_predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 7.2243, Top-5 Accuracy: 23.8276 \n",
      "Identification accuracy: 94.4257\n",
      "Top-1 Accuracy: 4.9430, Top-5 Accuracy: 17.4905 \n",
      "Identification accuracy: 91.6094\n",
      "Top-1 Accuracy: 4.6895, Top-5 Accuracy: 16.6033 \n",
      "Identification accuracy: 91.7746\n",
      "Top-1 Accuracy: 3.8544, Top-5 Accuracy: 17.1306 \n",
      "Identification accuracy: 91.1980\n"
     ]
    }
   ],
   "source": [
    "## concatenate image and text features to perform multimodal decoding\n",
    "\n",
    "multimodal_results = []\n",
    "\n",
    "for i,sub in enumerate([\"CSI1\",\"CSI2\",\"CSI3\",\"CSI4\"]):\n",
    "\n",
    "    pred_img_features = image_models[sub][\"test_predictions\"]\n",
    "    pred_text_features = text_models[sub][\"test_predictions\"]\n",
    "    true_img_features = image_models[sub][\"test_features\"]\n",
    "    true_text_features = text_models[sub][\"test_features\"]\n",
    "\n",
    "    pred_features = np.concatenate([pred_img_features,pred_text_features],1)\n",
    "    true_features = np.concatenate([true_img_features,true_text_features],1)\n",
    "\n",
    "    pred_features = torch.tensor(pred_features)\n",
    "    true_features = torch.tensor(true_features)\n",
    "\n",
    "    res = evaluate_and_log(pred_features.cpu().numpy(),true_features.cpu().numpy(),i+1)\n",
    "    multimodal_results.append(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Identification Accuracy (%)</th>\n",
       "      <th>ID Accuracy Baseline (%)</th>\n",
       "      <th>Top-1 Accuracy (%)</th>\n",
       "      <th>Top1 Baseline (%)</th>\n",
       "      <th>Top1 Improvement Over Baseline</th>\n",
       "      <th>Top-5 Accuracy (%)</th>\n",
       "      <th>Top5 Baseline (%)</th>\n",
       "      <th>Top5 Improvement Over Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>94.425733</td>\n",
       "      <td>50</td>\n",
       "      <td>7.224335</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>57.0</td>\n",
       "      <td>23.827630</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>91.609407</td>\n",
       "      <td>50</td>\n",
       "      <td>4.942966</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>39.0</td>\n",
       "      <td>17.490494</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>27.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>91.774591</td>\n",
       "      <td>50</td>\n",
       "      <td>4.689480</td>\n",
       "      <td>0.126743</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.603295</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>91.198041</td>\n",
       "      <td>50</td>\n",
       "      <td>3.854390</td>\n",
       "      <td>0.214133</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.130621</td>\n",
       "      <td>1.070664</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject  Identification Accuracy (%)  ID Accuracy Baseline (%)  \\\n",
       "0        1                    94.425733                        50   \n",
       "1        2                    91.609407                        50   \n",
       "2        3                    91.774591                        50   \n",
       "3        4                    91.198041                        50   \n",
       "\n",
       "   Top-1 Accuracy (%)  Top1 Baseline (%)  Top1 Improvement Over Baseline  \\\n",
       "0            7.224335           0.126743                            57.0   \n",
       "1            4.942966           0.126743                            39.0   \n",
       "2            4.689480           0.126743                            37.0   \n",
       "3            3.854390           0.214133                            18.0   \n",
       "\n",
       "   Top-5 Accuracy (%)  Top5 Baseline (%)  Top5 Improvement Over Baseline  \n",
       "0           23.827630           0.633714                            37.6  \n",
       "1           17.490494           0.633714                            27.6  \n",
       "2           16.603295           0.633714                            26.2  \n",
       "3           17.130621           1.070664                            16.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_multi = pd.DataFrame.from_dict(multimodal_results)\n",
    "df_multi.to_csv(\"/home/matteo/storage/brain_tuning/results_multi_linear.csv\")\n",
    "df_multi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braindiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
