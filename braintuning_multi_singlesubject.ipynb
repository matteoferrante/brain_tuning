{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook I'll train a brain to image and text features and combine their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nilearn \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join as opj\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from nilearn import plotting\n",
    "from nilearn.image import *\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import mean_img\n",
    "from nilearn.plotting import plot_img, plot_epi\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import wandb\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataset import fMRI_Dataset, fMRI_Multi_Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from network import Encoder, ContrastiveModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import importlib\n",
    "importlib.reload(dataset)\n",
    "from dataset import fMRI_Dataset, fMRI_Multi_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4td3l2qv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▅▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▄▄▅▅</td></tr><tr><td>subject_3_identification_accuracy</td><td>▁</td></tr><tr><td>subject_3_top1_acc</td><td>▁</td></tr><tr><td>subject_3_top5_acc</td><td>▁</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▃▃▂▂▁▁█▆▅▅▄▃</td></tr><tr><td>train_loss_step</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▅▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▄▄▅▅</td></tr><tr><td>val_cosine_similarity</td><td>▁▅▇████████▁▄▅▅▆▅</td></tr><tr><td>val_loss</td><td>▇▅▃▃▂▂▁▁▁▁▁█▆▅▄▄▄</td></tr><tr><td>val_mse_loss</td><td>▅▃▂▁▁▁▁▁▁▁▁█▆▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>subject_3_identification_accuracy</td><td>0.89703</td></tr><tr><td>subject_3_top1_acc</td><td>0.04183</td></tr><tr><td>subject_3_top5_acc</td><td>0.12801</td></tr><tr><td>train_loss_epoch</td><td>3.60227</td></tr><tr><td>train_loss_step</td><td>3.53726</td></tr><tr><td>trainer/global_step</td><td>47</td></tr><tr><td>val_cosine_similarity</td><td>0.14572</td></tr><tr><td>val_loss</td><td>4.9928</td></tr><tr><td>val_mse_loss</td><td>1.73616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ghostly-menace-43</strong> at: <a href='https://wandb.ai/matteoferrante/BrainTuning/runs/4td3l2qv' target=\"_blank\">https://wandb.ai/matteoferrante/BrainTuning/runs/4td3l2qv</a><br/> View project at: <a href='https://wandb.ai/matteoferrante/BrainTuning' target=\"_blank\">https://wandb.ai/matteoferrante/BrainTuning</a><br/>Synced 6 W&B file(s), 1 media file(s), 56 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241031_183606-4td3l2qv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4td3l2qv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matteo/brain_tuning/wandb/run-20241031_184333-3ciig4pz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matteoferrante/BrainTuning/runs/3ciig4pz' target=\"_blank\">ominous-trouble-44</a></strong> to <a href='https://wandb.ai/matteoferrante/BrainTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matteoferrante/BrainTuning' target=\"_blank\">https://wandb.ai/matteoferrante/BrainTuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matteoferrante/BrainTuning/runs/3ciig4pz' target=\"_blank\">https://wandb.ai/matteoferrante/BrainTuning/runs/3ciig4pz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/matteoferrante/BrainTuning/runs/3ciig4pz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f113872a6d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use_augmentations = True   \n",
    "sub = \"CSI4\"\n",
    "wandb.login()\n",
    "wandb.init(project=\"BrainTuning\",config={\"model\":\"multimodal\",\"single_subject\":True,  \"sub\":sub})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "## load the data\n",
    "\n",
    "train_datasets_images=[]\n",
    "val_datasets_images=[]\n",
    "test_datasets_images=[]\n",
    "\n",
    "train_datasets_text=[]\n",
    "val_datasets_text=[]\n",
    "test_datasets_text=[]\n",
    "\n",
    "\n",
    "for subj in tqdm.tqdm([sub]):\n",
    "\n",
    "    subj_id = int(subj.split(\"CSI\")[1])\n",
    "\n",
    "    data_path =  f\"/home/matteo/storage/brain_tuning/{subj}\"\n",
    "\n",
    "    train_fmri = np.load(opj(data_path, \"train_fmri_top.npy\"))\n",
    "    val_fmri = np.load(opj(data_path, \"val_fmri_top.npy\"))\n",
    "    test_fmri = np.load(opj(data_path, \"test_fmri_top.npy\"))\n",
    "\n",
    "    ##load the images\n",
    "    img_train = np.load(opj(data_path, \"img_train.npy\"),allow_pickle=True)\n",
    "    img_val = np.load(opj(data_path, \"img_val.npy\"),allow_pickle=True)\n",
    "    img_test = np.load(opj(data_path, \"img_test.npy\"),allow_pickle=True)\n",
    "\n",
    "     ##load the captions\n",
    "    train_captions = np.load(opj(data_path, \"train_captions.npy\"),allow_pickle=True)\n",
    "    val_captions = np.load(opj(data_path, \"val_captions.npy\"),allow_pickle=True)\n",
    "    test_captions = np.load(opj(data_path, \"test_captions.npy\"),allow_pickle=True)\n",
    "\n",
    "    ## load the features\n",
    "    train_features = np.load(opj(data_path, \"train_image_features.npy\"))\n",
    "    val_features = np.load(opj(data_path, \"val_image_features.npy\"))\n",
    "    test_features = np.load(opj(data_path, \"test_image_features.npy\"))\n",
    "\n",
    "    ## load the text features\n",
    "    train_text_features = np.load(opj(data_path, \"train_text_features.npy\"))\n",
    "    val_text_features = np.load(opj(data_path, \"val_text_features.npy\"))\n",
    "    test_text_features = np.load(opj(data_path, \"test_text_features.npy\"))\n",
    "\n",
    "    ## create the dataset\n",
    "    train_dataset = fMRI_Multi_Dataset(train_fmri,img_train,train_captions,train_features,train_text_features,subj_id,feature_type=\"image\")\n",
    "    val_dataset = fMRI_Multi_Dataset(val_fmri,img_val,val_captions,val_features,val_text_features,subj_id,feature_type=\"image\")\n",
    "    test_dataset = fMRI_Multi_Dataset(test_fmri,img_test,test_captions,test_features,test_text_features, subj_id,feature_type=\"image\")\n",
    "\n",
    "    ## append the datasets\n",
    "    train_datasets_images.append(train_dataset)\n",
    "    val_datasets_images.append(val_dataset)\n",
    "    test_datasets_images.append(test_dataset)\n",
    "\n",
    "    train_dataset_text = fMRI_Multi_Dataset(train_fmri,img_train,train_captions,train_features,train_text_features,subj_id,feature_type=\"text\")\n",
    "    val_dataset_text = fMRI_Multi_Dataset(val_fmri,img_val,val_captions,val_features,val_text_features,subj_id,feature_type=\"text\")\n",
    "    test_dataset_text = fMRI_Multi_Dataset(test_fmri,img_test,test_captions,test_features,test_text_features,subj_id,feature_type=\"text\")\n",
    "\n",
    "    ## append the datasets\n",
    "    train_datasets_text.append(train_dataset_text)\n",
    "    val_datasets_text.append(val_dataset_text)\n",
    "    test_datasets_text.append(test_dataset_text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the datasets\n",
    "train_dataset_images = torch.utils.data.ConcatDataset(train_datasets_images)\n",
    "val_dataset_images = torch.utils.data.ConcatDataset(val_datasets_images)\n",
    "test_dataset_images = torch.utils.data.ConcatDataset(test_datasets_images)\n",
    "\n",
    "train_dataset_text = torch.utils.data.ConcatDataset(train_datasets_text)\n",
    "val_dataset_text = torch.utils.data.ConcatDataset(val_datasets_text)\n",
    "test_dataset_text = torch.utils.data.ConcatDataset(test_datasets_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "train_loader = DataLoader(train_dataset_images, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_images, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset_images, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_loader_text = DataLoader(train_dataset_text, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_text = DataLoader(val_dataset_text, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader_text = DataLoader(test_dataset_text, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an Brain2ImageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimal parameter obtained from the hyperparameter search\n",
    "\n",
    "act_fn = nn.Identity\n",
    "base_channel_size = [2048]\n",
    "hidden_dims = [1024]\n",
    "latent_dim = 768\n",
    "\n",
    "loss_type = \"contrastive\"\n",
    "lr = 1e-4\n",
    "temperature = 0.1\n",
    "wd = 1e-5\n",
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/matteo/anaconda3/envs/borg/lib/python3.8/site- ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  | Name  | Type    | Params | Mode \n",
      "------------------------------------------\n",
      "0 | model | Encoder | 9.7 K  | train\n",
      "------------------------------------------\n",
      "9.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.7 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 397. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [00:02<00:00,  1.88it/s, v_num=g4pz, train_loss_step=4.860]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/borg/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 196. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [00:03<00:00,  1.61it/s, v_num=g4pz, train_loss_step=4.860, val_loss=5.450, val_mse_loss=1.810, val_cosine_similarity=0.0784, train_loss_epoch=6.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 5.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s, v_num=g4pz, train_loss_step=4.180, val_loss=5.210, val_mse_loss=1.740, val_cosine_similarity=0.115, train_loss_epoch=5.200] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.248 >= min_delta = 0.0. New best score: 5.206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 5/5 [00:03<00:00,  1.56it/s, v_num=g4pz, train_loss_step=3.750, val_loss=5.040, val_mse_loss=1.690, val_cosine_similarity=0.139, train_loss_epoch=4.740]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.162 >= min_delta = 0.0. New best score: 5.043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s, v_num=g4pz, train_loss_step=3.410, val_loss=4.930, val_mse_loss=1.660, val_cosine_similarity=0.154, train_loss_epoch=4.380]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.114 >= min_delta = 0.0. New best score: 4.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:03<00:00,  1.62it/s, v_num=g4pz, train_loss_step=3.120, val_loss=4.840, val_mse_loss=1.640, val_cosine_similarity=0.164, train_loss_epoch=4.060]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.085 >= min_delta = 0.0. New best score: 4.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:03<00:00,  1.42it/s, v_num=g4pz, train_loss_step=2.830, val_loss=4.780, val_mse_loss=1.630, val_cosine_similarity=0.167, train_loss_epoch=3.760]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.061 >= min_delta = 0.0. New best score: 4.783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:03<00:00,  1.65it/s, v_num=g4pz, train_loss_step=2.570, val_loss=4.740, val_mse_loss=1.630, val_cosine_similarity=0.169, train_loss_epoch=3.470]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.047 >= min_delta = 0.0. New best score: 4.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:03<00:00,  1.61it/s, v_num=g4pz, train_loss_step=2.270, val_loss=4.700, val_mse_loss=1.620, val_cosine_similarity=0.171, train_loss_epoch=3.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.040 >= min_delta = 0.0. New best score: 4.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:03<00:00,  1.45it/s, v_num=g4pz, train_loss_step=2.080, val_loss=4.660, val_mse_loss=1.620, val_cosine_similarity=0.173, train_loss_epoch=2.960]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.0. New best score: 4.665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s, v_num=g4pz, train_loss_step=1.930, val_loss=4.640, val_mse_loss=1.620, val_cosine_similarity=0.175, train_loss_epoch=2.730]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.025 >= min_delta = 0.0. New best score: 4.640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 5/5 [00:03<00:00,  1.61it/s, v_num=g4pz, train_loss_step=1.720, val_loss=4.620, val_mse_loss=1.620, val_cosine_similarity=0.176, train_loss_epoch=2.520]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 4.618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 5/5 [00:03<00:00,  1.56it/s, v_num=g4pz, train_loss_step=1.580, val_loss=4.600, val_mse_loss=1.610, val_cosine_similarity=0.177, train_loss_epoch=2.320]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 4.603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 5/5 [00:03<00:00,  1.57it/s, v_num=g4pz, train_loss_step=1.390, val_loss=4.590, val_mse_loss=1.610, val_cosine_similarity=0.177, train_loss_epoch=2.140]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: 4.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 5/5 [00:03<00:00,  1.44it/s, v_num=g4pz, train_loss_step=1.260, val_loss=4.580, val_mse_loss=1.610, val_cosine_similarity=0.178, train_loss_epoch=1.980]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 4.580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s, v_num=g4pz, train_loss_step=1.150, val_loss=4.570, val_mse_loss=1.610, val_cosine_similarity=0.178, train_loss_epoch=1.830]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 4.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 5/5 [00:03<00:00,  1.56it/s, v_num=g4pz, train_loss_step=1.050, val_loss=4.560, val_mse_loss=1.610, val_cosine_similarity=0.179, train_loss_epoch=1.700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 4.565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s, v_num=g4pz, train_loss_step=0.987, val_loss=4.560, val_mse_loss=1.610, val_cosine_similarity=0.179, train_loss_epoch=1.590]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 4.560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 5/5 [00:03<00:00,  1.56it/s, v_num=g4pz, train_loss_step=0.893, val_loss=4.560, val_mse_loss=1.610, val_cosine_similarity=0.178, train_loss_epoch=1.480]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 4.558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s, v_num=g4pz, train_loss_step=0.821, val_loss=4.560, val_mse_loss=1.610, val_cosine_similarity=0.179, train_loss_epoch=1.380]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 4.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 5/5 [00:03<00:00,  1.57it/s, v_num=g4pz, train_loss_step=0.710, val_loss=4.560, val_mse_loss=1.610, val_cosine_similarity=0.178, train_loss_epoch=1.300]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 4.556. Signaling Trainer to stop.\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 5/5 [00:03<00:00,  1.41it/s, v_num=g4pz, train_loss_step=0.710, val_loss=4.560, val_mse_loss=1.610, val_cosine_similarity=0.178, train_loss_epoch=1.300]\n"
     ]
    }
   ],
   "source": [
    "brain_image_model = ContrastiveModel(num_input_channels= 10000,\n",
    "                                base_channel_size=base_channel_size, \n",
    "                                hidden_dims=hidden_dims,\n",
    "                                latent_dim=latent_dim,\n",
    "                                act_fn=act_fn,\n",
    "                                loss_type=loss_type,\n",
    "                                lr = lr,\n",
    "                                wd = wd,\n",
    "                                alpha=alpha)\n",
    "\n",
    "# Set up early stopping to monitor 'val_loss'\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=1,verbose=True, mode='min')             # 'min' because we want to minimize val_loss\n",
    "wandb_logger = WandbLogger()  # Logs the model and metrics to wandb\n",
    "\n",
    "\n",
    "# Set up early stopping to monitor 'val_loss'\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=1,verbose=True, mode='min')             # 'min' because we want to minimize val_loss\n",
    "wandb_logger = WandbLogger()  # Logs the model and metrics to wandb\n",
    "\n",
    "\n",
    "# Create a unique checkpoint directory based on the run name or ID\n",
    "run_name = \"multimodal_model_IMAGE\"\n",
    "checkpoint_dir = os.path.join(data_path, \"models_multi\",sub, run_name)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Model checkpoint configuration\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss',dirpath=checkpoint_dir,filename='{sub}_brain_image_model-{epoch:02d}-{val_loss:.2f}',save_top_k=3,mode='min',)\n",
    "\n",
    "\n",
    "# Initialize trainer with logger\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, devices=[1], callbacks=[early_stop_callback,checkpoint_callback],logger=wandb_logger ) # Add the wandb logger here\n",
    "\n",
    "trainer.fit(brain_image_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type    | Params | Mode \n",
      "------------------------------------------\n",
      "0 | model | Encoder | 9.2 K  | train\n",
      "------------------------------------------\n",
      "9.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.2 K     Total params\n",
      "0.037     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  20%|██        | 1/5 [00:00<00:02,  1.63it/s, v_num=g4pz, train_loss_step=6.340]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [00:04<00:00,  1.23it/s, v_num=g4pz, train_loss_step=4.940, val_loss=5.560, val_mse_loss=1.880, val_cosine_similarity=0.0719, train_loss_epoch=6.040]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 5.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s, v_num=g4pz, train_loss_step=4.080, val_loss=5.370, val_mse_loss=1.820, val_cosine_similarity=0.101, train_loss_epoch=5.210] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.189 >= min_delta = 0.0. New best score: 5.367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 5/5 [00:03<00:00,  1.41it/s, v_num=g4pz, train_loss_step=3.730, val_loss=5.240, val_mse_loss=1.790, val_cosine_similarity=0.119, train_loss_epoch=4.730]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.126 >= min_delta = 0.0. New best score: 5.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:03<00:00,  1.66it/s, v_num=g4pz, train_loss_step=3.380, val_loss=5.140, val_mse_loss=1.760, val_cosine_similarity=0.132, train_loss_epoch=4.340]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.096 >= min_delta = 0.0. New best score: 5.145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:03<00:00,  1.66it/s, v_num=g4pz, train_loss_step=2.940, val_loss=5.080, val_mse_loss=1.750, val_cosine_similarity=0.137, train_loss_epoch=3.980]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.064 >= min_delta = 0.0. New best score: 5.081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:03<00:00,  1.52it/s, v_num=g4pz, train_loss_step=2.680, val_loss=5.050, val_mse_loss=1.750, val_cosine_similarity=0.138, train_loss_epoch=3.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.0. New best score: 5.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:03<00:00,  1.58it/s, v_num=g4pz, train_loss_step=2.450, val_loss=5.040, val_mse_loss=1.750, val_cosine_similarity=0.136, train_loss_epoch=3.350]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 5.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:03<00:00,  1.60it/s, v_num=g4pz, train_loss_step=2.250, val_loss=5.030, val_mse_loss=1.750, val_cosine_similarity=0.136, train_loss_epoch=3.060]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 5.035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:03<00:00,  1.40it/s, v_num=g4pz, train_loss_step=1.920, val_loss=5.040, val_mse_loss=1.750, val_cosine_similarity=0.135, train_loss_epoch=2.800]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 5.035. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:03<00:00,  1.27it/s, v_num=g4pz, train_loss_step=1.920, val_loss=5.040, val_mse_loss=1.750, val_cosine_similarity=0.135, train_loss_epoch=2.800]\n"
     ]
    }
   ],
   "source": [
    "brain_text_model = ContrastiveModel(num_input_channels= 10000,\n",
    "                                base_channel_size=base_channel_size, \n",
    "                                hidden_dims=hidden_dims,\n",
    "                                latent_dim=512,\n",
    "                                act_fn=act_fn,\n",
    "                                loss_type=loss_type,\n",
    "                                lr = lr,\n",
    "                                wd = wd,\n",
    "                                alpha=alpha)\n",
    "\n",
    "# Set up early stopping to monitor 'val_loss'\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=1,verbose=True, mode='min')             # 'min' because we want to minimize val_loss\n",
    "wandb_logger = WandbLogger()  # Logs the model and metrics to wandb\n",
    "\n",
    "\n",
    "# Set up early stopping to monitor 'val_loss'\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=1,verbose=True, mode='min')             # 'min' because we want to minimize val_loss\n",
    "wandb_logger = WandbLogger()  # Logs the model and metrics to wandb\n",
    "\n",
    "\n",
    "# Create a unique checkpoint directory based on the run name or ID\n",
    "run_name = run_name = \"multimodal_model_TEXT\"\n",
    "\n",
    "checkpoint_dir = os.path.join(data_path, \"models_multi\",sub, run_name)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Model checkpoint configuration\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss',dirpath=checkpoint_dir,filename='{sub}_TEXT_brain_text_model-{epoch:02d}-{val_loss:.2f}',save_top_k=3,mode='min',)\n",
    "\n",
    "\n",
    "# Initialize trainer with logger\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, devices=[1], callbacks=[early_stop_callback,checkpoint_callback],logger=wandb_logger ) # Add the wandb logger here\n",
    "\n",
    "trainer.fit(brain_text_model, train_loader_text, val_loader_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Evaluation:\n",
    "\n",
    "I'll wrap both models in a class, run predictions and concatenate outputs for subsequent evalautions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModelWrapper(nn.Module):\n",
    "    def __init__(self, image_model, text_model):\n",
    "        super(MultimodalModelWrapper, self).__init__()\n",
    "        self.image_model = image_model\n",
    "        self.text_model = text_model\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Extract relevant features from the batch\n",
    "\n",
    "        x = batch[\"data\"]\n",
    "        text_embed = batch[\"text_features\"]\n",
    "        img_embed = batch[\"image_features\"]\n",
    "        k = batch[\"subject_id\"]\n",
    "        # Pass features through each model\n",
    "        image_output,_ = self.image_model(x,img_embed,k=k)\n",
    "        text_output,_ = self.text_model(x,text_embed,k=k)\n",
    "\n",
    "        concatenated_embeddings = torch.cat((img_embed, text_embed), dim=-1)\n",
    "\n",
    "        # Concatenate outputs along the last dimension\n",
    "        combined_output = torch.cat((image_output, text_output), dim=-1)  # Shape: (batch_size, combined_dim)\n",
    "\n",
    "        return combined_output, concatenated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_model = MultimodalModelWrapper(brain_image_model, brain_text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "Evaluating metrics for subject 4...\n",
      "Computed similarity matrix for subject 4.\n",
      "Top-1 Accuracy: 0.0300, Top-5 Accuracy: 0.1435 for subject 4.\n",
      "Identification accuracy for subject 4: 0.8806\n",
      "Logged top-5 retrievals for subject 4.\n",
      "Evaluation complete. Results loaded to wandb.\n"
     ]
    }
   ],
   "source": [
    "import importlib \n",
    "import multi_evaluation\n",
    "importlib.reload(multi_evaluation)\n",
    "from multi_evaluation import *\n",
    "results_df, similarity_matrices, results = evaluate_and_log(test_loader_text,multimodal_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Identification Accuracy (%)</th>\n",
       "      <th>ID Accuracy Baseline (%)</th>\n",
       "      <th>Top-1 Accuracy (%)</th>\n",
       "      <th>Top1 Baseline (%)</th>\n",
       "      <th>Top1 Improvement Over Baseline</th>\n",
       "      <th>Top-5 Accuracy (%)</th>\n",
       "      <th>Top5 Baseline (%)</th>\n",
       "      <th>Top5 Improvement Over Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.057274</td>\n",
       "      <td>50</td>\n",
       "      <td>2.997859</td>\n",
       "      <td>0.214133</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.346895</td>\n",
       "      <td>1.070664</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject  Identification Accuracy (%)  ID Accuracy Baseline (%)  \\\n",
       "0        4                    88.057274                        50   \n",
       "\n",
       "   Top-1 Accuracy (%)  Top1 Baseline (%)  Top1 Improvement Over Baseline  \\\n",
       "0            2.997859           0.214133                            14.0   \n",
       "\n",
       "   Top-5 Accuracy (%)  Top5 Baseline (%)  Top5 Improvement Over Baseline  \n",
       "0           14.346895           1.070664                            13.4  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/home/matteo/storage/brain_tuning/\"\n",
    "results_df.to_csv(opj(output_path,f\"results_multi_contrastive_{sub}.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done CSI4\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\",sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
